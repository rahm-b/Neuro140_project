{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnBprBlvr5GQ",
        "outputId": "53f4512c-1048-4534-f4c1-0ecdce731b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Building wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=d86a0c56d5cf5b926488707b1f7108f9676f2f6db6584909e434516efc4f9bca\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: chess, python-chess\n",
            "Successfully installed chess-1.11.2 python-chess-1.999\n"
          ]
        }
      ],
      "source": [
        "!pip install python-chess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIapEQQosD_-",
        "outputId": "5b93013c-c3fc-4845-b6fa-4d80e402baa8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "\n",
        "# define piece names\n",
        "piece_names = {\n",
        "  'p': 'black pawn',   'P': 'white pawn',\n",
        "  'r': 'black rook',   'R': 'white rook',\n",
        "  'n': 'black knight', 'N': 'white knight',\n",
        "  'b': 'black bishop', 'B': 'white bishop',\n",
        "  'q': 'black queen',  'Q': 'white queen',\n",
        "  'k': 'black king',   'K': 'white king'\n",
        "}\n",
        "\n",
        "# convert FEN string to description of board state\n",
        "def fenToDescription(fen_string):\n",
        "\n",
        "  description = \"\"\n",
        "\n",
        "  # load chess board with the FEN\n",
        "  board = chess.Board(fen_string)\n",
        "\n",
        "  isFirstPiece = True\n",
        "  for square in chess.SQUARES:\n",
        "      piece = board.piece_at(square)\n",
        "      if piece:\n",
        "          piece_name = piece_names[piece.symbol()]\n",
        "\n",
        "          if isFirstPiece:\n",
        "            piece_name = piece_name[0].upper() + piece_name[1:]\n",
        "            isFirstPiece = False\n",
        "\n",
        "          description += f\"{piece_name} on {chess.square_name(square)}, \"\n",
        "\n",
        "  # replace comma at end with period\n",
        "  description = description[:-2] + '.'\n",
        "  return description\n",
        "\n",
        "\n",
        "# testing with example FEN\n",
        "fen_example = \"r1bqk2r/pPp2pbp/2np2p1/4p3/2B1n3/5N2/1PPP1PPP/RNBQK2R w KQkq - 1 8\"\n",
        "print(fenToDescription(fen_example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMmM6l6FsLN9",
        "outputId": "90f91e9f-2d7a-4461-ba7f-3e7431e42cb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White rook on a1, white knight on b1, white bishop on c1, white queen on d1, white king on e1, white rook on h1, white pawn on b2, white pawn on c2, white pawn on d2, white pawn on f2, white pawn on g2, white pawn on h2, white knight on f3, white bishop on c4, black knight on e4, black pawn on e5, black knight on c6, black pawn on d6, black pawn on g6, black pawn on a7, white pawn on b7, black pawn on c7, black pawn on f7, black bishop on g7, black pawn on h7, black rook on a8, black bishop on c8, black queen on d8, black king on e8, black rook on h8.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine all legal moves in a board state\n",
        "def generate_legal_moves(fen_string):\n",
        "    board = chess.Board(fen_string)\n",
        "    return [move.uci() for move in board.legal_moves]\n",
        "\n",
        "# test\n",
        "legal_moves = generate_legal_moves(fen_example)\n",
        "print(legal_moves)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWgFAqKysMG4",
        "outputId": "fad9fa7d-9e53-42da-cb02-e638242a9e47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['c4f7', 'c4e6', 'c4a6', 'c4d5', 'c4b5', 'c4d3', 'c4b3', 'c4e2', 'c4a2', 'c4f1', 'f3g5', 'f3e5', 'f3h4', 'f3d4', 'f3g1', 'h1g1', 'h1f1', 'e1e2', 'e1f1', 'd1e2', 'b1c3', 'b1a3', 'a1a7', 'a1a6', 'a1a5', 'a1a4', 'a1a3', 'a1a2', 'e1g1', 'b7c8q', 'b7c8r', 'b7c8b', 'b7c8n', 'b7a8q', 'b7a8r', 'b7a8b', 'b7a8n', 'b7b8q', 'b7b8r', 'b7b8b', 'b7b8n', 'h2h3', 'g2g3', 'd2d3', 'c2c3', 'b2b3', 'h2h4', 'g2g4', 'd2d4', 'b2b4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert move in chess notation into a textual description\n",
        "def describe_move(fen_string, move_uci):\n",
        "    board = chess.Board(fen_string)\n",
        "\n",
        "    move = chess.Move.from_uci(move_uci)\n",
        "\n",
        "    piece = board.piece_at(move.from_square)\n",
        "    if not piece:\n",
        "        return \"Invalid move: no piece on source square.\"\n",
        "\n",
        "    piece_names = {\n",
        "        'p': 'pawn', 'n': 'knight', 'b': 'bishop',\n",
        "        'r': 'rook', 'q': 'queen', 'k': 'king'\n",
        "    }\n",
        "\n",
        "    color = \"White\" if piece.color == chess.WHITE else \"Black\"\n",
        "    name = piece_names[piece.symbol().lower()]\n",
        "    from_sq = chess.square_name(move.from_square)\n",
        "    to_sq = chess.square_name(move.to_square)\n",
        "\n",
        "    # copy current board to apply the move\n",
        "    board_copy = board.copy()\n",
        "    board_copy.push(move)\n",
        "\n",
        "    # castling\n",
        "    if board.is_castling(move):\n",
        "        side = \"kingside\" if move.to_square > move.from_square else \"queenside\"\n",
        "        desc = f\"{color} castles {side}\"\n",
        "    # captures\n",
        "    elif board.is_capture(move):\n",
        "        if board.is_en_passant(move):\n",
        "            captured = 'pawn (en passant)'\n",
        "        else:\n",
        "            captured_piece = board.piece_at(move.to_square)\n",
        "            captured = piece_names[captured_piece.symbol().lower()] if captured_piece else \"unknown piece\"\n",
        "        desc = f\"{color} {name} captures {captured} on {to_sq}\"\n",
        "\n",
        "        # if it's a promotion too\n",
        "        if move.promotion:\n",
        "            promo_name = piece_names[chess.Piece(move.promotion, piece.color).symbol().lower()]\n",
        "            desc += f\" and promotes to a {promo_name}\"\n",
        "    # promotions\n",
        "    elif move.promotion:\n",
        "        promo_name = piece_names[chess.Piece(move.promotion, piece.color).symbol().lower()]\n",
        "        desc = f\"{color} {name} moves from {from_sq} to {to_sq} and promotes to a {promo_name}\"\n",
        "    # normal move otherwise\n",
        "    else:\n",
        "        desc = f\"{color} {name} moves from {from_sq} to {to_sq}\"\n",
        "\n",
        "    # checks or checkmates\n",
        "    if board_copy.is_checkmate():\n",
        "        desc += \" and delivers checkmate\"\n",
        "    elif board_copy.is_check():\n",
        "        desc += \" and delivers check\"\n",
        "\n",
        "    return desc + '.'\n",
        "\n",
        "for move in legal_moves:\n",
        "  print(f\"Move: {move}. Description: {describe_move(fen_example, move)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZe1m6b6sOFJ",
        "outputId": "f0d65943-76a4-4b21-97bb-164e7b0eb0a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Move: c4f7. Description: White bishop captures pawn on f7 and delivers check.\n",
            "Move: c4e6. Description: White bishop moves from c4 to e6.\n",
            "Move: c4a6. Description: White bishop moves from c4 to a6.\n",
            "Move: c4d5. Description: White bishop moves from c4 to d5.\n",
            "Move: c4b5. Description: White bishop moves from c4 to b5.\n",
            "Move: c4d3. Description: White bishop moves from c4 to d3.\n",
            "Move: c4b3. Description: White bishop moves from c4 to b3.\n",
            "Move: c4e2. Description: White bishop moves from c4 to e2.\n",
            "Move: c4a2. Description: White bishop moves from c4 to a2.\n",
            "Move: c4f1. Description: White bishop moves from c4 to f1.\n",
            "Move: f3g5. Description: White knight moves from f3 to g5.\n",
            "Move: f3e5. Description: White knight captures pawn on e5.\n",
            "Move: f3h4. Description: White knight moves from f3 to h4.\n",
            "Move: f3d4. Description: White knight moves from f3 to d4.\n",
            "Move: f3g1. Description: White knight moves from f3 to g1.\n",
            "Move: h1g1. Description: White rook moves from h1 to g1.\n",
            "Move: h1f1. Description: White rook moves from h1 to f1.\n",
            "Move: e1e2. Description: White king moves from e1 to e2.\n",
            "Move: e1f1. Description: White king moves from e1 to f1.\n",
            "Move: d1e2. Description: White queen moves from d1 to e2.\n",
            "Move: b1c3. Description: White knight moves from b1 to c3.\n",
            "Move: b1a3. Description: White knight moves from b1 to a3.\n",
            "Move: a1a7. Description: White rook captures pawn on a7.\n",
            "Move: a1a6. Description: White rook moves from a1 to a6.\n",
            "Move: a1a5. Description: White rook moves from a1 to a5.\n",
            "Move: a1a4. Description: White rook moves from a1 to a4.\n",
            "Move: a1a3. Description: White rook moves from a1 to a3.\n",
            "Move: a1a2. Description: White rook moves from a1 to a2.\n",
            "Move: e1g1. Description: White castles kingside.\n",
            "Move: b7c8q. Description: White pawn captures bishop on c8 and promotes to a queen.\n",
            "Move: b7c8r. Description: White pawn captures bishop on c8 and promotes to a rook.\n",
            "Move: b7c8b. Description: White pawn captures bishop on c8 and promotes to a bishop.\n",
            "Move: b7c8n. Description: White pawn captures bishop on c8 and promotes to a knight.\n",
            "Move: b7a8q. Description: White pawn captures rook on a8 and promotes to a queen.\n",
            "Move: b7a8r. Description: White pawn captures rook on a8 and promotes to a rook.\n",
            "Move: b7a8b. Description: White pawn captures rook on a8 and promotes to a bishop.\n",
            "Move: b7a8n. Description: White pawn captures rook on a8 and promotes to a knight.\n",
            "Move: b7b8q. Description: White pawn moves from b7 to b8 and promotes to a queen.\n",
            "Move: b7b8r. Description: White pawn moves from b7 to b8 and promotes to a rook.\n",
            "Move: b7b8b. Description: White pawn moves from b7 to b8 and promotes to a bishop.\n",
            "Move: b7b8n. Description: White pawn moves from b7 to b8 and promotes to a knight.\n",
            "Move: h2h3. Description: White pawn moves from h2 to h3.\n",
            "Move: g2g3. Description: White pawn moves from g2 to g3.\n",
            "Move: d2d3. Description: White pawn moves from d2 to d3.\n",
            "Move: c2c3. Description: White pawn moves from c2 to c3.\n",
            "Move: b2b3. Description: White pawn moves from b2 to b3.\n",
            "Move: h2h4. Description: White pawn moves from h2 to h4.\n",
            "Move: g2g4. Description: White pawn moves from g2 to g4.\n",
            "Move: d2d4. Description: White pawn moves from d2 to d4.\n",
            "Move: b2b4. Description: White pawn moves from b2 to b4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY RUN THIS CELL FOR CHESS-SPECIFIC BERT\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# load chess-specific BERT model\n",
        "bert_path_trained = \"/content/drive/MyDrive/chess-bert-mlm/final_model\""
      ],
      "metadata": {
        "id": "9EQmgzNHsQ7O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINING THE DRRN MODEL\n",
        "\n",
        "\"\"\"Inspiration from Singh et. al. from https://arxiv.org/pdf/2107.08408.\n",
        "Their DRRN framework: https://github.com/Exploration-Lab/IFG-Pretrained-LM/blob/main/dbert_drrn/model.py\n",
        "My framework is inspired from them,  but simipler and modified for chess\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "class DRRN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, lm_path=\"bert-base-uncased\", custom_model=False):\n",
        "        super(DRRN, self).__init__()\n",
        "\n",
        "        # if not using custom model\n",
        "        if custom_model == False:\n",
        "            self.tokenizer = BertTokenizer.from_pretrained(lm_path)\n",
        "            self.bert = BertModel.from_pretrained(lm_path)\n",
        "\n",
        "        # if custom model, user different tokenizer and load model differently\n",
        "        else:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(lm_path)\n",
        "            self.bert = AutoModel.from_pretrained(lm_path)\n",
        "\n",
        "        self.bert.eval()\n",
        "        self.state_proj = nn.Linear(self.bert.config.hidden_size, hidden_dim)\n",
        "        self.action_proj = nn.Linear(self.bert.config.hidden_size, hidden_dim)\n",
        "        self.q_proj = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    # encode states and actions using the BERT [cls] token embedding\n",
        "    def encode(self, texts):\n",
        "        encoding = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "        input_ids, attention_mask = encoding['input_ids'].to(device), encoding['attention_mask'].to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    def forward(self, state_batch, act_batch):\n",
        "        state_texts = [s[0] for s in state_batch]\n",
        "        state_vecs = self.state_proj(self.encode(state_texts))\n",
        "\n",
        "        q_values = []\n",
        "        for s_vec, acts in zip(state_vecs, act_batch):\n",
        "            act_vecs = self.action_proj(self.encode(acts))\n",
        "            scores = self.q_proj(torch.tanh(s_vec.unsqueeze(0) * act_vecs)).squeeze(-1)\n",
        "            q_values.append(scores)\n",
        "        return q_values\n",
        "\n",
        "    # decide moves to play with greedy-epsilon\n",
        "    def act(self, state_batch, act_batch, epsilon=0.1):\n",
        "        q_values = self.forward(state_batch, act_batch)\n",
        "        chosen_idxs = []\n",
        "        for qv in q_values:\n",
        "            if random.random() < epsilon:\n",
        "                chosen_idxs.append(random.randint(0, len(qv) - 1))\n",
        "            else:\n",
        "                chosen_idxs.append(torch.argmax(qv).item())\n",
        "        return chosen_idxs, q_values"
      ],
      "metadata": {
        "id": "XZLzkhN6sYnQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for simulating games. This function is a random move generator that is able to play against the model.\n",
        "def apply_move(fen_string, move):\n",
        "  board = chess.Board(fen_string)\n",
        "  game_over = False\n",
        "  result = None\n",
        "\n",
        "  move_obj = chess.Move.from_uci(move)\n",
        "\n",
        "  board.push(move_obj)\n",
        "\n",
        "  # print(board)\n",
        "\n",
        "  # check if game is over after model plays a move\n",
        "  if board.is_game_over():\n",
        "      game_over = True\n",
        "      board_result = board.result()\n",
        "      if board_result == \"1/2-1/2\":\n",
        "        result = 0\n",
        "        print(\"DRAW\")\n",
        "      else: # if a player won after the bot played a move, it must mean the bot performed checkmate\n",
        "        result = 1\n",
        "        print(\"BOT WINS\") # Model wins\n",
        "\n",
        "      return None, fen_string, game_over, result\n",
        "\n",
        "  # get all legal moves in the current position\n",
        "  legal_moves = list(board.legal_moves)\n",
        "\n",
        "  # select a random move from the legal moves\n",
        "  random_move = random.choice(legal_moves)\n",
        "\n",
        "  # apply the random move to the board\n",
        "  board.push(random_move)\n",
        "\n",
        "  new_fen_state = board.fen()\n",
        "\n",
        "  if board.is_game_over():\n",
        "      game_over = True\n",
        "      board_result = board.result()\n",
        "      if board_result == \"1/2-1/2\":\n",
        "        result = 0\n",
        "        print(\"DRAW\")\n",
        "\n",
        "      # if a player won after the user (random move generator) played a move,\n",
        "      # it must mean the user performed checkmate\n",
        "      else:\n",
        "        result = -1\n",
        "        print(\"USER WINS\")\n",
        "\n",
        "\n",
        "  return str(random_move), new_fen_state, game_over, result"
      ],
      "metadata": {
        "id": "O0yuZ9cvsdRj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.engine\n",
        "\n",
        "# install Stockfish chess engine into Colab environment\n",
        "!apt-get install stockfish\n",
        "\n",
        "engine = chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\")\n",
        "\n",
        "def get_best_move(fen):\n",
        "  board = chess.Board(fen)\n",
        "\n",
        "  # Get Stockfish's best move\n",
        "  result = engine.play(board, chess.engine.Limit(time=0.1))  # Play with a time limit (e.g., 2 seconds)\n",
        "  return str(result.move)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK_uy52RsgGA",
        "outputId": "32a27e01-5a1c-48ae-c3d6-090b87188979"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  polyglot xboard | scid\n",
            "The following NEW packages will be installed:\n",
            "  stockfish\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 24.8 MB of archives.\n",
            "After this operation, 47.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 stockfish amd64 14.1-1 [24.8 MB]\n",
            "Fetched 24.8 MB in 4s (6,056 kB/s)\n",
            "Selecting previously unselected package stockfish.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../stockfish_14.1-1_amd64.deb ...\n",
            "Unpacking stockfish (14.1-1) ...\n",
            "Setting up stockfish (14.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_move(\"rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "71oP4VYWsiN2",
        "outputId": "8a1e82c7-6ac5-481b-b7fa-8527260799d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c7c5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PGN string from a list of moves in a chess game\n",
        "def move_list_to_pgn(move_list):\n",
        "  # create a new game and get the board from it\n",
        "  game = chess.pgn.Game()\n",
        "  node = game\n",
        "\n",
        "  board = game.board()\n",
        "\n",
        "  # apply moves\n",
        "  for uci_move in move_list:\n",
        "      move = board.parse_uci(uci_move)\n",
        "      board.push(move)\n",
        "      node = node.add_variation(move)\n",
        "\n",
        "  # return pgn\n",
        "  return(game)\n",
        "\n",
        "\n",
        "def move_to_pgn_with_comments(move_comment_list, result):\n",
        "  # convert result int into string\n",
        "  result_str = \"\"\n",
        "  if result == 1:\n",
        "    result_str = \"1-0\"\n",
        "  elif result == 0:\n",
        "    result_str = \"1/2-1/2\"\n",
        "  else:\n",
        "    result_str = \"0-1\"\n",
        "\n",
        "  # create game and get board\n",
        "  game = chess.pgn.Game()\n",
        "  node = game\n",
        "  board = game.board()\n",
        "\n",
        "  # add moves with comments\n",
        "  for uci, comment in move_comment_list:\n",
        "      move = board.parse_uci(uci)\n",
        "      board.push(move)\n",
        "      node = node.add_variation(move)\n",
        "      node.comment = comment\n",
        "\n",
        "  game.headers[\"White\"] = \"BOT\"\n",
        "  game.headers[\"Black\"] = \"RANDOM\"\n",
        "  game.headers[\"Result\"] = result_str\n",
        "\n",
        "  # return pgn\n",
        "  return(game)\n",
        "\n",
        "\n",
        "import os\n",
        "os.makedirs(\"/content/drive/MyDrive/chess_training\", exist_ok=True)\n",
        "\n",
        "def add_game_to_pgn_file(game_pgn):\n",
        "  with open(\"many_games_trained.pgn\", \"a\") as f:\n",
        "      f.write(str(game_pgn) + \"\\n\\n\")\n",
        "\n",
        "  # also add/update file to drive to make sure data is not lost\n",
        "  # drive_path = \"/content/drive/MyDrive/chess_training/many_games_vanilla.pgn\" # ONLY USE FOR BERT-BASE\n",
        "  drive_path = \"/content/drive/MyDrive/chess_training/many_games_trained.pgn\" # ONLY USE FOR CHESS-PRETRAINED MODEL\n",
        "\n",
        "\n",
        "  with open(drive_path, \"a\") as f:\n",
        "      f.write(str(game_pgn) + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "lyOgb6MOslKy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to continually save model while training\n",
        "\n",
        "import os\n",
        "\n",
        "# checkpoint_dir = \"/content/drive/MyDrive/checkpoints_DRRN/base\"  # for vanilla BERT-base model\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints_DRRN/chess\"  # for chess-specific BERT model\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"drrn_checkpoint.pth\")\n",
        "\n",
        "def save_checkpoint(model, optimizer, episode, path):\n",
        "    torch.save({\n",
        "        'episode': episode,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)\n",
        "    print(f\"Checkpoint saved to {path}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, path):\n",
        "    if os.path.exists(path):\n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_episode = checkpoint['episode'] + 1\n",
        "        print(f\"Loaded checkpoint from episode {checkpoint['episode']}\")\n",
        "    else:\n",
        "        start_episode = 0\n",
        "        print(\"No checkpoint found. Starting from scratch.\")\n",
        "    return start_episode"
      ],
      "metadata": {
        "id": "JHmAcUE3syS_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.engine\n",
        "import torch\n",
        "import random\n",
        "import chess.pgn\n",
        "\n",
        "# USE THIS ONE FOR BERT-BASE\n",
        "# drrn = DRRN(vocab_size=None, embedding_dim=256, hidden_dim=128).to(device)\n",
        "\n",
        "# USE THIS ONE FOR THE PRETRAINED BERT ON CHESS TEXTS\n",
        "drrn = DRRN(vocab_size=None, embedding_dim=256, hidden_dim=128, lm_path=bert_path_trained, custom_model=True).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(drrn.parameters(), lr=1e-4)\n",
        "engine = chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\")\n",
        "\n",
        "# load saved model if we are continuing to train it\n",
        "start_episode = load_checkpoint(drrn, optimizer, checkpoint_path)\n",
        "\n",
        "def get_best_move(fen):\n",
        "    board = chess.Board(fen)\n",
        "    result = engine.play(board, chess.engine.Limit(time=0.1))  # give Stockfish 0.1 seconds to make a move\n",
        "    return result.move.uci()\n",
        "\n",
        "def compute_reward(recorded_state, chosen_move, best_move):\n",
        "  # evaluate position before move\n",
        "  board = chess.Board(recorded_state)\n",
        "  info_before = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
        "  score_before = info_before[\"score\"].white().score(mate_score=1000)  # get score in centipawns\n",
        "  if abs(score_before) > 1000:\n",
        "    score_before = (1000 / abs(score_before)) * score_before  # max score is +/- 10.0\n",
        "\n",
        "  # play chosen move\n",
        "  move = chess.Move.from_uci(chosen_move)\n",
        "  board.push(move)\n",
        "\n",
        "  # evaluate position after move\n",
        "  info_after = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
        "  score_after = info_after[\"score\"].white().score(mate_score=1000)\n",
        "  if abs(score_after) > 1000:\n",
        "    score_after = (1000 / abs(score_after)) * score_after  # max score is +/- 10.0\n",
        "\n",
        "  # calculate centipawn loss\n",
        "  cpl = (score_before - score_after) if board.turn == chess.BLACK else (score_before - score_after)\n",
        "  cpl = max(cpl, 0)  # only include loss if move worsened position\n",
        "\n",
        "\n",
        "  # if centipawn loss is over 100, we want to start penalizing\n",
        "  reward = -(cpl - 100) / (100 * 20)\n",
        "\n",
        "  # increase reward extra of cps is under 100\n",
        "  if cpl < 100:\n",
        "    reward = 0.5 - .005 * cpl\n",
        "\n",
        "  # so reward ranges from -1 to 0.5 b/c max cpl is 2000\n",
        "\n",
        "  return(reward)\n",
        "\n",
        "\n",
        "# TRAINING\n",
        "game_results = []\n",
        "\n",
        "for episode in range(300):  # number of games to train on\n",
        "    game_memory = []\n",
        "    state = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
        "    done = False\n",
        "\n",
        "    game_moves = []\n",
        "    while not done:\n",
        "        state_desc = fenToDescription(state)\n",
        "        legal_uci_moves = generate_legal_moves(state)\n",
        "        move_descs = [describe_move(state, move) for move in legal_uci_moves]\n",
        "\n",
        "        state_batch = [(state_desc, \"\", \"\", \"\")]\n",
        "        act_batch = [move_descs]\n",
        "\n",
        "        # the model chooses a move\n",
        "        chosen_idx, _ = drrn.act(state_batch, act_batch, epsilon=0.2)\n",
        "        chosen_move = legal_uci_moves[chosen_idx[0]]\n",
        "        game_moves.append(chosen_move)\n",
        "\n",
        "        # store the move and the state for later comparison with Stockfish evaluations\n",
        "        game_memory.append((state_desc, legal_uci_moves, move_descs, chosen_idx[0], state))\n",
        "\n",
        "        # apply the move to the chess board\n",
        "        opp_move, state, done, result = apply_move(state, chosen_move)\n",
        "        if not (opp_move == None):\n",
        "          game_moves.append(opp_move)\n",
        "\n",
        "    game_pgn = move_list_to_pgn(game_moves)\n",
        "\n",
        "    final_reward = result\n",
        "    game_results.append(result)\n",
        "\n",
        "    # after the game ends, get Stockfish's evaluations for each recorded position\n",
        "    moves_with_comments = []\n",
        "    for i in range(len(game_memory)):\n",
        "        state_desc, legal_uci_moves, move_descs, chosen_idx, recorded_state = game_memory[i]\n",
        "\n",
        "        # get Stockfish's best move for the recorded state\n",
        "        best_move = get_best_move(recorded_state)\n",
        "\n",
        "        # get the move played by the model\n",
        "        chosen_move = legal_uci_moves[chosen_idx]\n",
        "\n",
        "        # calculate the reward based on the model's move compared to Stockfish evaluations\n",
        "        reward = compute_reward(recorded_state, chosen_move, best_move)\n",
        "\n",
        "        moves_with_comments.append((game_moves[2 * i], f\"Best move: {best_move}. Reward: {reward}.\"))\n",
        "\n",
        "        # update memory with the reward\n",
        "        game_memory[i] = (*game_memory[i][:-1], reward)\n",
        "\n",
        "        # add move from opponent\n",
        "        if len(game_moves) > 2 * i + 1:\n",
        "          moves_with_comments.append((game_moves[2 * i + 1], \"\"))\n",
        "\n",
        "\n",
        "    # get PGN of the chess game and add it to our PGN file\n",
        "    pgn_with_comments = move_to_pgn_with_comments(moves_with_comments, result)\n",
        "    add_game_to_pgn_file(pgn_with_comments)\n",
        "\n",
        "    # update the model with the rewards for all moves in the game\n",
        "    for state_desc, legal_uci_moves, move_descs, chosen_idx, reward in game_memory:\n",
        "        state_batch = [(state_desc, \"\", \"\", \"\")]\n",
        "        act_batch = [move_descs]\n",
        "\n",
        "        q_values = drrn(state_batch, act_batch)[0]\n",
        "        q_value = q_values[chosen_idx]\n",
        "\n",
        "        # calculate loss and backpropagate\n",
        "        combined_reward = 0.5 * reward + 0.5 * final_reward\n",
        "        loss = (q_value - combined_reward) ** 2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Episode {episode} done. Reward: {final_reward}\")\n",
        "\n",
        "    # save after every episode\n",
        "    save_checkpoint(drrn, optimizer, episode, checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ALnoT40s06i",
        "outputId": "e4aae599-7e48-48d8-f822-0317de56a09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/chess-bert-mlm/final_model and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint from episode 127\n",
            "DRAW\n",
            "Episode 0 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 1 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 2 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 3 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "BOT WINS\n",
            "Episode 4 done. Reward: 1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 5 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 6 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 7 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 8 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 9 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 10 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 11 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 12 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 13 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 14 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 15 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 16 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "BOT WINS\n",
            "Episode 17 done. Reward: 1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 18 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 19 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 20 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "BOT WINS\n",
            "Episode 21 done. Reward: 1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 22 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 23 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 24 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 25 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "BOT WINS\n",
            "Episode 26 done. Reward: 1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 27 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 28 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 29 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 30 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 31 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 32 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 33 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 34 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 35 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 36 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 37 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 38 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 39 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 40 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 41 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "BOT WINS\n",
            "Episode 42 done. Reward: 1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 43 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 44 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 45 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 46 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 47 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 48 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 49 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 50 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 51 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 52 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 53 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 54 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 55 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 56 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 57 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 58 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 59 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 60 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 61 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 62 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 63 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 64 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 65 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 66 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 67 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 68 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 69 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 70 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 71 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 72 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 73 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 74 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 75 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 76 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "USER WINS\n",
            "Episode 77 done. Reward: -1\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n",
            "Episode 78 done. Reward: 0\n",
            "Checkpoint saved to /content/drive/MyDrive/checkpoints_DRRN/chess/drrn_checkpoint.pth\n",
            "DRAW\n"
          ]
        }
      ]
    }
  ]
}